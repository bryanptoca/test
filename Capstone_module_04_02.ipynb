{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3137186",
   "metadata": {},
   "source": [
    "\n",
    "Bryan Chi Fai Pang\n",
    "\n",
    "Student ID: 501210081\n",
    "\n",
    "TMU: The Chang School of Continuing Education\n",
    "\n",
    "CIND 820 Big Data Analytics Project\n",
    "\n",
    "Dr Ceni BABAOGLU\n",
    "\n",
    "10 November 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a59c0a6",
   "metadata": {},
   "source": [
    "#### Github Repository\n",
    "\n",
    "\n",
    "https://github.com/bryantoca/capstone_project\n",
    "\n",
    "Please note this notebook takse around 15 mintues to run / render.\n",
    "An html version as well as NBViewer version are available on line.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d118d47",
   "metadata": {},
   "source": [
    "# Initial Results and Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404146b2-842c-4d04-a8f8-97c9b1077432",
   "metadata": {},
   "source": [
    "## Part 1: Creation of Train, Validation, and Test Sets\n",
    "\n",
    "1. **Train-Validate-Final Test Split:**\n",
    "\n",
    "    - 80% train-validate split, 20% test set.\n",
    "    - Anomaly records removed from train-validate sets.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "2. **Handling Abnormal Records:**\n",
    "\n",
    "    - Records with zero credit taken and grades throughout university but labeled as 'Graduate' moved.\n",
    "\n",
    "\n",
    "\n",
    "3. **Target Mapping:**\n",
    "\n",
    "    - Strings converted to numeric using the following mapping:\n",
    "        {'Dropout': 0, 'Enrolled': 1, 'Graduate': 2}\n",
    "\n",
    "\n",
    "## Part 2: Model Selection Using 10-fold Cross Validation\n",
    "\n",
    "Using the following models:\n",
    "- Logistic Regression\n",
    "- Random Forest (n_estimators=10 and n_estimators=100)\n",
    "- Support Vector Machine (SVM)\n",
    "- SVM with a linear kernel\n",
    "- Gradient Boosting\n",
    "- XGB Classifier\n",
    "\n",
    "Performance Metrics:\n",
    "- Average Accuracy\n",
    "- Average F1 Score\n",
    "- Standard Deviation (SD)\n",
    "\n",
    "## Part 3: Research Question Analysis\n",
    "\n",
    "Subsets of the dataset are trained and tested using Random Forest and XGB Classifier with 80-20 train-validate split.\n",
    "\n",
    "Subsets:\n",
    "1. S1: Academic, Macroeconomic\n",
    "2. S2: Academic, Macroeconomics, Demographic\n",
    "3. S3: Academic, Macroeconomics, Socioeconomic\n",
    "4. S4: Academic, Macroeconomic, Demographic, Socioeconomic\n",
    "5. S5: Demographic, Socioeconomic\n",
    "\n",
    "Full Classification Reports are displayed for each subset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df0d0a4",
   "metadata": {},
   "source": [
    "## Part 1: Creation of Train, Validation, and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "630fd225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary libraries\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.font_manager as fm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from xgboost import XGBClassifier  \n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from statistics import mean, stdev\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ca06ab0-f88e-4cf3-81a8-0558d561d4b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook started at  2023-11-22 16:18:54.072282\n"
     ]
    }
   ],
   "source": [
    "# Using the datetime.now() at the beginning and at the end to check time \n",
    "# needed to run the codes.\n",
    "\n",
    "# datetime object containing current date and time\n",
    "Start = datetime.now()\n",
    " \n",
    "print(\"Notebook started at \", Start )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e0328f",
   "metadata": {},
   "source": [
    "1. **Train-Validate-Final Test Split:**\n",
    "    - 80% train-validate split, 20% test set (this test set is not use but for final test /results)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56615f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating train_valide and test_set \n",
    "# test_set is for final testing\n",
    "\n",
    "data = pd.read_csv(\"data.csv\",sep=\";\") \n",
    "\n",
    "#data = pd.read_csv(\"data_cat.csv\", sep=\";\")\n",
    "\n",
    "#train_validate_set, test_set = train_test_split(df, test_size = 0.2, random_state=76)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab9b3f9",
   "metadata": {},
   "source": [
    "- Anomaly Detection : records removed from train-validate sets.\n",
    "These records are students that are classified as \"Graduate\", but with zero for all curricular units taken as well as zero as grades. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59370319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Curricular units 1st sem (credited)</th>\n",
       "      <th>Curricular units 1st sem (enrolled)</th>\n",
       "      <th>Curricular units 1st sem (evaluations)</th>\n",
       "      <th>Curricular units 1st sem (approved)</th>\n",
       "      <th>Curricular units 1st sem (grade)</th>\n",
       "      <th>Curricular units 1st sem (without evaluations)</th>\n",
       "      <th>Curricular units 2nd sem (credited)</th>\n",
       "      <th>Curricular units 2nd sem (enrolled)</th>\n",
       "      <th>Curricular units 2nd sem (evaluations)</th>\n",
       "      <th>Curricular units 2nd sem (approved)</th>\n",
       "      <th>Curricular units 2nd sem (grade)</th>\n",
       "      <th>Curricular units 2nd sem (without evaluations)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Graduate</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Graduate</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Graduate</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>Graduate</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>Graduate</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Target  Curricular units 1st sem (credited)  \\\n",
       "20   Graduate                                    0   \n",
       "66   Graduate                                    0   \n",
       "101  Graduate                                    0   \n",
       "405  Graduate                                    0   \n",
       "527  Graduate                                    0   \n",
       "\n",
       "     Curricular units 1st sem (enrolled)  \\\n",
       "20                                     0   \n",
       "66                                     0   \n",
       "101                                    0   \n",
       "405                                    0   \n",
       "527                                    0   \n",
       "\n",
       "     Curricular units 1st sem (evaluations)  \\\n",
       "20                                        0   \n",
       "66                                        0   \n",
       "101                                       0   \n",
       "405                                       0   \n",
       "527                                       0   \n",
       "\n",
       "     Curricular units 1st sem (approved)  Curricular units 1st sem (grade)  \\\n",
       "20                                     0                               0.0   \n",
       "66                                     0                               0.0   \n",
       "101                                    0                               0.0   \n",
       "405                                    0                               0.0   \n",
       "527                                    0                               0.0   \n",
       "\n",
       "     Curricular units 1st sem (without evaluations)  \\\n",
       "20                                                0   \n",
       "66                                                0   \n",
       "101                                               0   \n",
       "405                                               0   \n",
       "527                                               0   \n",
       "\n",
       "     Curricular units 2nd sem (credited)  Curricular units 2nd sem (enrolled)  \\\n",
       "20                                     0                                    0   \n",
       "66                                     0                                    0   \n",
       "101                                    0                                    0   \n",
       "405                                    0                                    0   \n",
       "527                                    0                                    0   \n",
       "\n",
       "     Curricular units 2nd sem (evaluations)  \\\n",
       "20                                        0   \n",
       "66                                        0   \n",
       "101                                       0   \n",
       "405                                       0   \n",
       "527                                       0   \n",
       "\n",
       "     Curricular units 2nd sem (approved)  Curricular units 2nd sem (grade)  \\\n",
       "20                                     0                               0.0   \n",
       "66                                     0                               0.0   \n",
       "101                                    0                               0.0   \n",
       "405                                    0                               0.0   \n",
       "527                                    0                               0.0   \n",
       "\n",
       "     Curricular units 2nd sem (without evaluations)  \n",
       "20                                                0  \n",
       "66                                                0  \n",
       "101                                               0  \n",
       "405                                               0  \n",
       "527                                               0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "anomalies = data[(data['Target'] == 'Graduate') & (data.iloc[:, 21:33].eq(0).all(axis=1))]\n",
    "anomalies_to_print = anomalies[[\"Target\"]+list(data.columns[21:33])]\n",
    "anomalies_to_print.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47689193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([  20,   66,  101,  405,  527,  534,  557,  574,  679,  722,  728,\n",
       "             789,  821,  869,  881, 1002, 1050, 1192, 1302, 1350, 1363, 1377,\n",
       "            1425, 1507, 1512, 1575, 1585, 1600, 1658, 1751, 1883, 1889, 1890,\n",
       "            1898, 2008, 2026, 2124, 2143, 2175, 2194, 2230, 2235, 2328, 2356,\n",
       "            2371, 2387, 2406, 2496, 2508, 2637, 2656, 2793, 2814, 2899, 2920,\n",
       "            2955, 3023, 3024, 3135, 3160, 3317, 3405, 3447, 3481, 3683, 3707,\n",
       "            3717, 3732, 3745, 3928, 3946, 4291, 4353, 4365, 4370],\n",
       "           dtype='int64')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anomal = data[(data['Target'] == 'Graduate') & (data.iloc[:, 21:33].eq(0).all(axis=1))]\n",
    "anomal.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c435da6d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3e0ffd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(anomal.index,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3595c82a",
   "metadata": {},
   "source": [
    "3. **Target Mapping:**\n",
    "    - Strings converted to numeric using the following mapping:\n",
    "        {'Dropout': 0, 'Enrolled': 1, 'Graduate': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graduate    2134\n",
      "Dropout     1421\n",
      "Enrolled     794\n",
      "Name: Target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data_counts = data['Target'].value_counts()\n",
    "\n",
    "print(data_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d0f98d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ef700ade",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af2992ee-5fd6-4a57-918a-ff94bc011141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4349 entries, 0 to 4423\n",
      "Data columns (total 37 columns):\n",
      " #   Column                                          Non-Null Count  Dtype  \n",
      "---  ------                                          --------------  -----  \n",
      " 0   Marital status                                  4349 non-null   int64  \n",
      " 1   Application mode                                4349 non-null   int64  \n",
      " 2   Application order                               4349 non-null   int64  \n",
      " 3   Course                                          4349 non-null   int64  \n",
      " 4   Daytime evening attendance                      4349 non-null   int64  \n",
      " 5   Previous qualification                          4349 non-null   int64  \n",
      " 6   Previous qualification (grade)                  4349 non-null   float64\n",
      " 7   Nacionality                                     4349 non-null   int64  \n",
      " 8   Mother's qualification                          4349 non-null   int64  \n",
      " 9   Father's qualification                          4349 non-null   int64  \n",
      " 10  Mother's occupation                             4349 non-null   int64  \n",
      " 11  Father's occupation                             4349 non-null   int64  \n",
      " 12  Admission grade                                 4349 non-null   float64\n",
      " 13  Displaced                                       4349 non-null   int64  \n",
      " 14  Educational special needs                       4349 non-null   int64  \n",
      " 15  Debtor                                          4349 non-null   int64  \n",
      " 16  Tuition fees up to date                         4349 non-null   int64  \n",
      " 17  Gender                                          4349 non-null   int64  \n",
      " 18  Scholarship holder                              4349 non-null   int64  \n",
      " 19  Age at enrollment                               4349 non-null   int64  \n",
      " 20  International                                   4349 non-null   int64  \n",
      " 21  Curricular units 1st sem (credited)             4349 non-null   int64  \n",
      " 22  Curricular units 1st sem (enrolled)             4349 non-null   int64  \n",
      " 23  Curricular units 1st sem (evaluations)          4349 non-null   int64  \n",
      " 24  Curricular units 1st sem (approved)             4349 non-null   int64  \n",
      " 25  Curricular units 1st sem (grade)                4349 non-null   float64\n",
      " 26  Curricular units 1st sem (without evaluations)  4349 non-null   int64  \n",
      " 27  Curricular units 2nd sem (credited)             4349 non-null   int64  \n",
      " 28  Curricular units 2nd sem (enrolled)             4349 non-null   int64  \n",
      " 29  Curricular units 2nd sem (evaluations)          4349 non-null   int64  \n",
      " 30  Curricular units 2nd sem (approved)             4349 non-null   int64  \n",
      " 31  Curricular units 2nd sem (grade)                4349 non-null   float64\n",
      " 32  Curricular units 2nd sem (without evaluations)  4349 non-null   int64  \n",
      " 33  Unemployment rate                               4349 non-null   float64\n",
      " 34  Inflation rate                                  4349 non-null   float64\n",
      " 35  GDP                                             4349 non-null   float64\n",
      " 36  Target                                          4349 non-null   int64  \n",
      "dtypes: float64(7), int64(30)\n",
      "memory usage: 1.3 MB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create a mapping dicctionary for Target, as XGBoost take only numeric value.\n",
    "mapping = {'Dropout':0, 'Enrolled':0, 'Graduate':1}\n",
    "\n",
    "data['Target']=data['Target'].map(mapping)\n",
    "\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a25b31b",
   "metadata": {},
   "source": [
    "## Part 2: Model Selection Using 10-fold Cross Validation\n",
    "\n",
    "Using the following models:\n",
    "\n",
    "- Random Forest (n_estimators=10 and n_estimators=100)\n",
    "- Support Vector Machine (SVM)\n",
    "- SVM with a linear kernel\n",
    "- Gradient Boosting\n",
    "- XGB Classifier\n",
    "\n",
    "Performance Metrics:\n",
    "- Average Accuracy\n",
    "- Average F1 Score\n",
    "- Standard Deviation (SD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593e9fc7",
   "metadata": {},
   "source": [
    "Using 10-fold cross validation to give an initial results to see how different algorithms.\n",
    "\n",
    "First, for each algorithm, F1 and Accuracy  is reported of each fold and then average F1 and Accuracy, as well as SD are reported. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf93091-dbc8-41af-8b07-e9bc83afd505",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47f24dd",
   "metadata": {},
   "source": [
    "Summary of these models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6bbf61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8c1aeeca",
   "metadata": {},
   "source": [
    "#### Results\n",
    "\n",
    "Of the 6 models trained, Random Forest (n_estimator=100), Gradient Boosting and XGB Classifer have the highest accuracy and F1 score.\n",
    "\n",
    "Based on these results, the project will focus of these three models and continue with  feature selection / feature engineering as well \n",
    "model hyperparametr tuning.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0431081e",
   "metadata": {},
   "source": [
    "## Part 3: Research Question Analysis\n",
    "\n",
    "Research question:\n",
    "\n",
    "Dose inclusion of Demographic and Socioeconmoic data improve dropout prediction, and by how much ?\n",
    "To annsewer the question, subsets of datasets are created and for initial results, Random Forest and XGB Classifier are used.\n",
    "\n",
    "For each subset, Classification Report, Feature Importance and Permutation Importance are showned.\n",
    "\n",
    "Subsets of the dataset are trained and tested using Random Forest and XGB Classifier with 80-20 train-validate split.\n",
    "\n",
    "Subsets:\n",
    "1. S1: Academic, Macroeconomic\n",
    "2. S2: Academic, Macroeconomics, Demographic\n",
    "3. S3: Academic, Macroeconomics, Socioeconomic\n",
    "4. S4: Academic, Macroeconomic, Demographic, Socioeconomic\n",
    "5. S5: Demographic, Socioeconomic\n",
    "\n",
    "Full Classification Reports are displayed for each subset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b2e200",
   "metadata": {},
   "source": [
    "Creating the subsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demographic Columns\n",
    "- Marital status\n",
    "- Nacionality\n",
    "- Displaced\n",
    "- Gender\n",
    "- Age at enrollment\n",
    "- International\n",
    "\n",
    "### Socioeconomic Columns\n",
    "- Mother's qualification\n",
    "- Father's qualification\n",
    "- Mother's occupation\n",
    "- Father's occupation\n",
    "- Educational special needs\n",
    "- Debtor\n",
    "- Tuition fees up to date\n",
    "- Scholarship holder\n",
    "\n",
    "### Macroeconomic Columns\n",
    "- Unemployment rate\n",
    "- Inflation rate\n",
    "- GDP\n",
    "\n",
    "### Academic Columns\n",
    "- Application mode\n",
    "- Application order\n",
    "- Course\n",
    "- Daytime evening attendance\n",
    "- Previous qualification\n",
    "- Previous qualification (grade)\n",
    "- Admission grade\n",
    "- Curricular units 1st sem (credited)\n",
    "- Curricular units 1st sem (enrolled)\n",
    "- Curricular units 1st sem (evaluations)\n",
    "- Curricular units 1st sem (approved)\n",
    "- Curricular units 1st sem (grade)\n",
    "- Curricular units 1st sem (without evaluations)\n",
    "- Curricular units 2nd sem (credited)\n",
    "- Curricular units 2nd sem (enrolled)\n",
    "- Curricular units 2nd sem (evaluations)\n",
    "- Curricular units 2nd sem (approved)\n",
    "- Curricular units 2nd sem (grade)\n",
    "- Curricular units 2nd sem (without evaluations)\n",
    "\n",
    "### Target Column\n",
    "- Target\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49d01832",
   "metadata": {},
   "outputs": [],
   "source": [
    "demographic_columns = ['Marital status','Nacionality','Displaced','Gender','Age at enrollment','International']\n",
    "socioeconomic_columns =[\"Mother's qualification\",\"Father's qualification\",\"Mother's occupation\",\"Father's occupation\",'Educational special needs','Debtor',\n",
    " 'Tuition fees up to date','Scholarship holder']\n",
    "macroeconomic_columns = ['Unemployment rate','Inflation rate','GDP']\n",
    "academic_columns = [\n",
    " 'Application mode',\n",
    " 'Application order',\n",
    " 'Course',\n",
    " 'Daytime evening attendance',\n",
    " 'Previous qualification',\n",
    " 'Previous qualification (grade)',\n",
    " 'Admission grade',\n",
    " 'Curricular units 1st sem (credited)',\n",
    " 'Curricular units 1st sem (enrolled)',\n",
    " 'Curricular units 1st sem (evaluations)',\n",
    " 'Curricular units 1st sem (approved)',\n",
    " 'Curricular units 1st sem (grade)',\n",
    " 'Curricular units 1st sem (without evaluations)',\n",
    " 'Curricular units 2nd sem (credited)',\n",
    " 'Curricular units 2nd sem (enrolled)',\n",
    " 'Curricular units 2nd sem (evaluations)',\n",
    " 'Curricular units 2nd sem (approved)',\n",
    " 'Curricular units 2nd sem (grade)',\n",
    " 'Curricular units 2nd sem (without evaluations)'\n",
    " ]\n",
    "target_s = ['Target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8193aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = data[target_s + macroeconomic_columns + academic_columns]\n",
    "s2 = data[target_s + macroeconomic_columns + academic_columns + demographic_columns]\n",
    "s3 = data[target_s + macroeconomic_columns + academic_columns + socioeconomic_columns]\n",
    "s4 = data[target_s + macroeconomic_columns + academic_columns + socioeconomic_columns + demographic_columns]\n",
    "s5 = data[target_s + demographic_columns + socioeconomic_columns ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "13a04afd",
   "metadata": {},
   "source": [
    "The 5 datasets with Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a36059dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for s1:\n",
      "Attribute Groups: Academic, Macroeconomic\n",
      "Accuracy: 0.8529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " No Graduate       0.88      0.83      0.86       457\n",
      "    Graduate       0.82      0.88      0.85       413\n",
      "\n",
      "    accuracy                           0.85       870\n",
      "   macro avg       0.85      0.85      0.85       870\n",
      "weighted avg       0.85      0.85      0.85       870\n",
      "\n",
      "-------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for s2:\n",
      "Attribute Groups: Academic, Macroeconomics, Demographic\n",
      "Accuracy: 0.8552\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " No Graduate       0.89      0.82      0.86       457\n",
      "    Graduate       0.82      0.89      0.85       413\n",
      "\n",
      "    accuracy                           0.86       870\n",
      "   macro avg       0.86      0.86      0.86       870\n",
      "weighted avg       0.86      0.86      0.86       870\n",
      "\n",
      "-------------------------------------------------------------\n",
      "\n",
      "Results for s3:\n",
      "Attribute Groups: Academic, Macroeconomics, Socioeconomic\n",
      "Accuracy: 0.8575\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " No Graduate       0.89      0.83      0.86       457\n",
      "    Graduate       0.83      0.89      0.86       413\n",
      "\n",
      "    accuracy                           0.86       870\n",
      "   macro avg       0.86      0.86      0.86       870\n",
      "weighted avg       0.86      0.86      0.86       870\n",
      "\n",
      "-------------------------------------------------------------\n",
      "\n",
      "Results for s4:\n",
      "Attribute Groups: Academic, Macroeconomic, Demographic, Socioeconomic\n",
      "Accuracy: 0.8563\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " No Graduate       0.88      0.84      0.86       457\n",
      "    Graduate       0.83      0.88      0.85       413\n",
      "\n",
      "    accuracy                           0.86       870\n",
      "   macro avg       0.86      0.86      0.86       870\n",
      "weighted avg       0.86      0.86      0.86       870\n",
      "\n",
      "-------------------------------------------------------------\n",
      "\n",
      "Results for s5:\n",
      "Attribute Groups: Demographic, Socioeconomic\n",
      "Accuracy: 0.6586\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " No Graduate       0.68      0.66      0.67       457\n",
      "    Graduate       0.64      0.66      0.65       413\n",
      "\n",
      "    accuracy                           0.66       870\n",
      "   macro avg       0.66      0.66      0.66       870\n",
      "weighted avg       0.66      0.66      0.66       870\n",
      "\n",
      "-------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "dataframes = [s1, s2, s3, s4, s5]  \n",
    "\n",
    "attribute_groups = [\n",
    "    ['Academic', 'Macroeconomic'],\n",
    "    ['Academic', 'Macroeconomics', 'Demographic'],\n",
    "    ['Academic', 'Macroeconomics', 'Socioeconomic'],\n",
    "    ['Academic', 'Macroeconomic', 'Demographic', 'Socioeconomic'],\n",
    "    ['Demographic', 'Socioeconomic']\n",
    "]\n",
    "\n",
    "\n",
    "results = []\n",
    "\n",
    "for i, df in enumerate(dataframes, 1):\n",
    "    target = df[\"Target\"]\n",
    "    features = df.drop(\"Target\", axis=1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=76)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "       \n",
    "\n",
    "\n",
    "\n",
    "    rf_classifier = RandomForestClassifier(n_estimators=100, random_state=76)\n",
    "    rf_classifier.fit(X_train, y_train)\n",
    "    predictions = rf_classifier.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    target_names = ['No Graduate', 'Graduate']\n",
    "    report = classification_report(y_test, predictions, target_names=target_names)\n",
    "    results.append((accuracy, report))\n",
    "\n",
    "    print(f\"Results for s{i}:\")\n",
    "    print(f\"Attribute Groups: {', '.join(attribute_groups[i - 1])}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(report)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Confusion Matrix without normalization\n",
    "    cm = confusion_matrix(y_test, predictions)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=target_names, yticklabels=target_names)\n",
    "    plt.title(f'Confusion Matrix without Normalization - Attribute Groups: {\", \".join(attribute_groups[i - 1])}')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.show()\n",
    "\n",
    "    # Confusion Matrix with normalization\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm_normalized, annot=True, fmt=\".2f\", cmap=\"Blues\", xticklabels=target_names, yticklabels=target_names)\n",
    "    plt.title(f'Confusion Matrix with Normalization - Attribute Groups: {\", \".join(attribute_groups[i - 1])}')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    feature_importance = rf_classifier.feature_importances_\n",
    "    feature_names = list(X_train.columns)\n",
    "\n",
    "    # Create a DataFrame with feature names and their importances\n",
    "    feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importance})\n",
    "    feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "    # Plotting feature importances\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(range(len(feature_importance_df)), feature_importance_df['Importance'], align='center')\n",
    "    plt.xticks(range(len(feature_importance_df)), feature_importance_df['Feature'], rotation='vertical')\n",
    "    plt.xlabel('Features')\n",
    "    plt.ylabel('Importance')\n",
    "    plt.title(f'Random Forest Feature Importance for s{i} - Attribute Groups: {\", \".join(attribute_groups[i - 1])}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    result = permutation_importance(rf_classifier, X_test, y_test, n_repeats=10, random_state=42, n_jobs=2)\n",
    "\n",
    "    sorted_importances_idx = result.importances_mean.argsort()\n",
    "    importances = pd.DataFrame(\n",
    "        result.importances[sorted_importances_idx].T,\n",
    "        columns=X_train.columns[sorted_importances_idx],\n",
    "    )\n",
    "\n",
    "    ax = importances.plot.box(vert=False, whis=10)\n",
    "    ax.set_title(f\"Permutation Importances (test set) - Attribute Groups: {', '.join(attribute_groups[i - 1])}\")\n",
    "    ax.axvline(x=0, color=\"k\", linestyle=\"--\")\n",
    "    ax.set_xlabel(\"Decrease in accuracy score\")\n",
    "    ax.figure.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "\"\"\"\n",
    "    print(\"-------------------------------------------------------------\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 5 datasets with Gradient Booster Classifer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for s1:\n",
      "Attribute Groups: Academic, Macroeconomic\n",
      "Accuracy: 0.8563\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " No Graduate       0.90      0.81      0.86       457\n",
      "    Graduate       0.81      0.90      0.86       413\n",
      "\n",
      "    accuracy                           0.86       870\n",
      "   macro avg       0.86      0.86      0.86       870\n",
      "weighted avg       0.86      0.86      0.86       870\n",
      "\n",
      "-------------------------------------------------------------\n",
      "\n",
      "Results for s2:\n",
      "Attribute Groups: Academic, Macroeconomics, Demographic\n",
      "Accuracy: 0.8552\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " No Graduate       0.90      0.81      0.85       457\n",
      "    Graduate       0.81      0.90      0.86       413\n",
      "\n",
      "    accuracy                           0.86       870\n",
      "   macro avg       0.86      0.86      0.86       870\n",
      "weighted avg       0.86      0.86      0.86       870\n",
      "\n",
      "-------------------------------------------------------------\n",
      "\n",
      "Results for s3:\n",
      "Attribute Groups: Academic, Macroeconomics, Socioeconomic\n",
      "Accuracy: 0.8563\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " No Graduate       0.89      0.83      0.86       457\n",
      "    Graduate       0.83      0.88      0.85       413\n",
      "\n",
      "    accuracy                           0.86       870\n",
      "   macro avg       0.86      0.86      0.86       870\n",
      "weighted avg       0.86      0.86      0.86       870\n",
      "\n",
      "-------------------------------------------------------------\n",
      "\n",
      "Results for s4:\n",
      "Attribute Groups: Academic, Macroeconomic, Demographic, Socioeconomic\n",
      "Accuracy: 0.8540\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " No Graduate       0.89      0.83      0.86       457\n",
      "    Graduate       0.82      0.88      0.85       413\n",
      "\n",
      "    accuracy                           0.85       870\n",
      "   macro avg       0.85      0.86      0.85       870\n",
      "weighted avg       0.86      0.85      0.85       870\n",
      "\n",
      "-------------------------------------------------------------\n",
      "\n",
      "Results for s5:\n",
      "Attribute Groups: Demographic, Socioeconomic\n",
      "Accuracy: 0.7011\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " No Graduate       0.72      0.70      0.71       457\n",
      "    Graduate       0.68      0.70      0.69       413\n",
      "\n",
      "    accuracy                           0.70       870\n",
      "   macro avg       0.70      0.70      0.70       870\n",
      "weighted avg       0.70      0.70      0.70       870\n",
      "\n",
      "-------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataframes = [s1, s2, s3, s4, s5]  \n",
    "\n",
    "attribute_groups = [\n",
    "    ['Academic', 'Macroeconomic'],\n",
    "    ['Academic', 'Macroeconomics', 'Demographic'],\n",
    "    ['Academic', 'Macroeconomics', 'Socioeconomic'],\n",
    "    ['Academic', 'Macroeconomic', 'Demographic', 'Socioeconomic'],\n",
    "    ['Demographic', 'Socioeconomic']\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "results = []\n",
    "for i, df in enumerate(dataframes, 1):\n",
    "    target = df[\"Target\"]\n",
    "    features = df.drop(\"Target\", axis=1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=76)\n",
    " \n",
    "    GB_classifier = GradientBoostingClassifier( random_state=76)\n",
    "    GB_classifier.fit(X_train, y_train)\n",
    "    predictions = GB_classifier.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    target_names = [ 'No Graduate', 'Graduate']\n",
    "    report = classification_report(y_test, predictions, target_names=target_names)\n",
    "    results.append((accuracy, report))\n",
    "\n",
    "    print(f\"Results for s{i}:\")\n",
    "    print(f\"Attribute Groups: {', '.join(attribute_groups[i - 1])}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(report)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Confusion Matrix without normalization\n",
    "    cm = confusion_matrix(y_test, predictions)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=target_names, yticklabels=target_names)\n",
    "    plt.title(f'Confusion Matrix without Normalization - Attribute Groups: {\", \".join(attribute_groups[i - 1])}')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.show()\n",
    "\n",
    "    # Confusion Matrix with normalization\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm_normalized, annot=True, fmt=\".2f\", cmap=\"Blues\", xticklabels=target_names, yticklabels=target_names)\n",
    "    plt.title(f'Confusion Matrix with Normalization - Attribute Groups: {\", \".join(attribute_groups[i - 1])}')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.show()\n",
    "\n",
    "    feature_importance = GB_classifier.feature_importances_\n",
    "    feature_names = list(X_train.columns)\n",
    "\n",
    "    # Create a DataFrame with feature names and their importances\n",
    "    feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importance})\n",
    "    feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "    # Plotting feature importances\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(range(len(feature_importance_df)), feature_importance_df['Importance'], align='center')\n",
    "    plt.xticks(range(len(feature_importance_df)), feature_importance_df['Feature'], rotation='vertical')\n",
    "    plt.xlabel('Features')\n",
    "    plt.ylabel('Importance')\n",
    "    plt.title(f'GB Feature Importance for s{i} - Attribute Groups: {\", \".join(attribute_groups[i - 1])}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    result = permutation_importance(GB_classifier, X_test, y_test, n_repeats=10, random_state=42, n_jobs=2)\n",
    "\n",
    "    sorted_importances_idx = result.importances_mean.argsort()\n",
    "    importances = pd.DataFrame(\n",
    "        result.importances[sorted_importances_idx].T,\n",
    "        columns=X_train.columns[sorted_importances_idx],\n",
    "    )\n",
    "\n",
    "    ax = importances.plot.box(vert=False, whis=10)\n",
    "    ax.set_title(f\"Permutation Importances (test set) - Attribute Groups: {', '.join(attribute_groups[i - 1])}\")\n",
    "    ax.axvline(x=0, color=\"k\", linestyle=\"--\")\n",
    "    ax.set_xlabel(\"Decrease in accuracy score\")\n",
    "    ax.figure.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    print(\"-------------------------------------------------------------\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db43f50",
   "metadata": {},
   "source": [
    "The 5 datasets with XGB Classifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e24d0c9a-f13e-4235-a16d-aceefcfdee7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for s1:\n",
      "Attribute Groups: Academic, Macroeconomic\n",
      "Accuracy: 0.8483\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Not Graduate       0.87      0.83      0.85       457\n",
      "    Graduate       0.82      0.87      0.84       413\n",
      "\n",
      "    accuracy                           0.85       870\n",
      "   macro avg       0.85      0.85      0.85       870\n",
      "weighted avg       0.85      0.85      0.85       870\n",
      "\n",
      "-------------------------------------------------------------\n",
      "\n",
      "Results for s2:\n",
      "Attribute Groups: Academic, Macroeconomics, Demographic\n",
      "Accuracy: 0.8471\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Not Graduate       0.88      0.82      0.85       457\n",
      "    Graduate       0.81      0.88      0.85       413\n",
      "\n",
      "    accuracy                           0.85       870\n",
      "   macro avg       0.85      0.85      0.85       870\n",
      "weighted avg       0.85      0.85      0.85       870\n",
      "\n",
      "-------------------------------------------------------------\n",
      "\n",
      "Results for s3:\n",
      "Attribute Groups: Academic, Macroeconomics, Socioeconomic\n",
      "Accuracy: 0.8621\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Not Graduate       0.89      0.84      0.86       457\n",
      "    Graduate       0.83      0.89      0.86       413\n",
      "\n",
      "    accuracy                           0.86       870\n",
      "   macro avg       0.86      0.86      0.86       870\n",
      "weighted avg       0.86      0.86      0.86       870\n",
      "\n",
      "-------------------------------------------------------------\n",
      "\n",
      "Results for s4:\n",
      "Attribute Groups: Academic, Macroeconomic, Demographic, Socioeconomic\n",
      "Accuracy: 0.8471\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Not Graduate       0.87      0.83      0.85       457\n",
      "    Graduate       0.82      0.86      0.84       413\n",
      "\n",
      "    accuracy                           0.85       870\n",
      "   macro avg       0.85      0.85      0.85       870\n",
      "weighted avg       0.85      0.85      0.85       870\n",
      "\n",
      "-------------------------------------------------------------\n",
      "\n",
      "Results for s5:\n",
      "Attribute Groups: Demographic, Socioeconomic\n",
      "Accuracy: 0.6920\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Not Graduate       0.73      0.66      0.69       457\n",
      "    Graduate       0.66      0.73      0.69       413\n",
      "\n",
      "    accuracy                           0.69       870\n",
      "   macro avg       0.69      0.69      0.69       870\n",
      "weighted avg       0.70      0.69      0.69       870\n",
      "\n",
      "-------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "dataframes = [s1, s2, s3, s4, s5]  # \n",
    "\n",
    "attribute_groups = [\n",
    "    ['Academic', 'Macroeconomic'],\n",
    "    ['Academic', 'Macroeconomics', 'Demographic'],\n",
    "    ['Academic', 'Macroeconomics', 'Socioeconomic'],\n",
    "    ['Academic', 'Macroeconomic', 'Demographic', 'Socioeconomic'],\n",
    "    ['Demographic', 'Socioeconomic']\n",
    "]\n",
    "\n",
    "\n",
    "results = []\n",
    "for i, df in enumerate(dataframes, 1):\n",
    "    target = df[\"Target\"]\n",
    "    features = df.drop(\"Target\", axis=1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=76)\n",
    "    xgb_classifier = XGBClassifier(objective='multi:softmax', num_class=2, random_state=76)\n",
    "    xgb_classifier.fit(X_train, y_train)\n",
    "    predictions = xgb_classifier.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    target_names = ['Not Graduate', 'Graduate']\n",
    "    report = classification_report(y_test, predictions, target_names=target_names)\n",
    "    results.append((accuracy, report))\n",
    "\n",
    "    print(f\"Results for s{i}:\")\n",
    "    print(f\"Attribute Groups: {', '.join(attribute_groups[i - 1])}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(report)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Confusion Matrix without normalization\n",
    "    cm = confusion_matrix(y_test, predictions)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=target_names, yticklabels=target_names)\n",
    "    plt.title(f'Confusion Matrix without Normalization - Attribute Groups: {\", \".join(attribute_groups[i - 1])}')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.show()\n",
    "\n",
    "    # Confusion Matrix with normalization\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm_normalized, annot=True, fmt=\".2f\", cmap=\"Blues\", xticklabels=target_names, yticklabels=target_names)\n",
    "    plt.title(f'Confusion Matrix with Normalization - Attribute Groups: {\", \".join(attribute_groups[i - 1])}')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.show()\n",
    "\n",
    "    # Feature Importance\n",
    "    feature_importance = xgb_classifier.feature_importances_\n",
    "    feature_names = list(X_train.columns)\n",
    "\n",
    "    # Create a DataFrame with feature names and their importances\n",
    "    feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importance})\n",
    "    feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "    # Plotting feature importances\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(range(len(feature_importance_df)), feature_importance_df['Importance'], align='center')\n",
    "    plt.xticks(range(len(feature_importance_df)), feature_importance_df['Feature'], rotation='vertical')\n",
    "    plt.xlabel('Features')\n",
    "    plt.ylabel('Importance')\n",
    "    plt.title(f'XGB Classifier Feature Importance for s{i} - Attribute Groups: {\", \".join(attribute_groups[i - 1])}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Permutation Importance\n",
    "    result = permutation_importance(xgb_classifier, X_test, y_test, n_repeats=10, random_state=42, n_jobs=2)\n",
    "    sorted_importances_idx = result.importances_mean.argsort()\n",
    "    importances = pd.DataFrame(\n",
    "        result.importances[sorted_importances_idx].T,\n",
    "        columns=X_test.columns[sorted_importances_idx],\n",
    "    )\n",
    "\n",
    "    ax = importances.plot.box(vert=False, whis=10)\n",
    "    ax.set_title(f\"Permutation Importances (test set) - Attribute Groups: {', '.join(attribute_groups[i - 1])}\")\n",
    "    ax.axvline(x=0, color=\"k\", linestyle=\"--\")\n",
    "    ax.set_xlabel(\"Decrease in accuracy score\")\n",
    "    ax.figure.tight_layout()\n",
    "    plt.show()\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "\n",
    "    print(\"-------------------------------------------------------------\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d96056",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "30f254f3",
   "metadata": {},
   "source": [
    "Model Random Forest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a9b6a3",
   "metadata": {},
   "source": [
    "### Summary of Confusion Matrices Model Random Forest\n",
    "\n",
    "|  Subset  | Attribute Groups                              | Accuracy | Precision (No Graduate) | Recall (No Graduate) | F1-Score (No Graduate) | Precision (Graduate) | Recall (Graduate) | F1-Score (Graduate) | Macro Avg | Weighted Avg |\n",
    "|----|-----------------------------------------------|----------|-------------------------|----------------------|-------------------------|----------------------|-------------------|----------------------|-----------|--------------|\n",
    "| s1 | Academic, Macroeconomic                       | 0.8529   | 0.88                    | 0.83                 | 0.86                    | 0.82                 | 0.88              | 0.85                 | 0.85      | 0.85         |\n",
    "| s2 | Academic, Macroeconomics, Demographic          | 0.8552   | 0.89                    | 0.82                 | 0.86                    | 0.82                 | 0.89              | 0.85                 | 0.86      | 0.86         |\n",
    "| s3 | Academic, Macroeconomics, Socioeconomic        | 0.8575   | 0.89                    | 0.83                 | 0.86                    | 0.83                 | 0.89              | 0.86                 | 0.86      | 0.86         |\n",
    "| s4 | Academic, Macroeconomic, Demographic, Socioeconomic | 0.8563   | 0.88                    | 0.84                 | 0.86                    | 0.83                 | 0.88              | 0.85                 | 0.86      | 0.86         |\n",
    "| s5 | Demographic, Socioeconomic                    | 0.6586   | 0.68                    | 0.66                 | 0.67                    | 0.64                 | 0.66              | 0.65                 | 0.66      | 0.66         |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49050156",
   "metadata": {},
   "source": [
    "\n",
    "Model Gardien Boosting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7154d8",
   "metadata": {},
   "source": [
    "### Summary of Confusion Matrices Model Gardien Boosting\n",
    "\n",
    "|  Subset  | Attribute Groups                              | Accuracy | Precision (No Graduate) | Recall (No Graduate) | F1-Score (No Graduate) | Precision (Graduate) | Recall (Graduate) | F1-Score (Graduate) | Macro Avg | Weighted Avg |\n",
    "|----|-----------------------------------------------|----------|-------------------------|----------------------|-------------------------|----------------------|-------------------|----------------------|-----------|--------------|\n",
    "| s1 | Academic, Macroeconomic                       | 0.8563   | 0.90                    | 0.81                 | 0.86                    | 0.81                 | 0.90              | 0.86                 | 0.86      | 0.86         |\n",
    "| s2 | Academic, Macroeconomics, Demographic          | 0.8552   | 0.90                    | 0.81                 | 0.85                    | 0.81                 | 0.90              | 0.86                 | 0.86      | 0.86         |\n",
    "| s3 | Academic, Macroeconomics, Socioeconomic        | 0.8563   | 0.89                    | 0.83                 | 0.86                    | 0.83                 | 0.88              | 0.85                 | 0.86      | 0.86         |\n",
    "| s4 | Academic, Macroeconomic, Demographic, Socioeconomic | 0.8540   | 0.89                    | 0.83                 | 0.86                    | 0.82                 | 0.88              | 0.85                 | 0.85      | 0.85         |\n",
    "| s5 | Demographic, Socioeconomic                    | 0.7011   | 0.72                    | 0.70                 | 0.71                    | 0.68                 | 0.70              | 0.69                 | 0.70      | 0.70         |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f7509a",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of Confusion Matrices Model XGBoost\n",
    "\n",
    "|  Subset  | Attribute Groups                              | Accuracy | Precision (Not Graduate) | Recall (Not Graduate) | F1-Score (Not Graduate) | Precision (Graduate) | Recall (Graduate) | F1-Score (Graduate) | Macro Avg | Weighted Avg |\n",
    "|----|-----------------------------------------------|----------|--------------------------|-----------------------|--------------------------|-----------------------|-------------------|----------------------|-----------|--------------|\n",
    "| s1 | Academic, Macroeconomic                       | 0.8483   | 0.87                     | 0.83                  | 0.85                     | 0.82                  | 0.87              | 0.84                 | 0.85      | 0.85         |\n",
    "| s2 | Academic, Macroeconomics, Demographic          | 0.8471   | 0.88                     | 0.82                  | 0.85                     | 0.81                  | 0.88              | 0.85                 | 0.85      | 0.85         |\n",
    "| s3 | Academic, Macroeconomics, Socioeconomic        | 0.8621   | 0.89                     | 0.84                  | 0.86                     | 0.83                  | 0.89              | 0.86                 | 0.86      | 0.86         |\n",
    "| s4 | Academic, Macroeconomic, Demographic, Socioeconomic | 0.8471   | 0.87                     | 0.83                  | 0.85                     | 0.82                  | 0.86              | 0.84                 | 0.85      | 0.85         |\n",
    "| s5 | Demographic, Socioeconomic                    | 0.6920   | 0.73                     | 0.66                  | 0.69                     | 0.66                  | 0.73              | 0.69                 | 0.69      | 0.70         |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbc9f56-ec28-4e3b-ba92-cea58effa03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608be6d3",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05123d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde3f8f1-e1ab-46f6-954e-8d769ba554ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "daa40ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook ended at  2023-11-22 16:19:09.898706\n"
     ]
    }
   ],
   "source": [
    "end = datetime.now()\n",
    " \n",
    "print(\"Notebook ended at \", end )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82a43f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6316cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ddef69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d705d165",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4c7785",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pydata-book",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
